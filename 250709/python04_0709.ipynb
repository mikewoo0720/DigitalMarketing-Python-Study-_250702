{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7c6ae70-b701-4700-80bd-e33b4c04463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "<h1 id=\"title\">[1]크롤링이란?</h1>\n",
      "[1]크롤링이란?\n",
      "[1]크롤링이란?\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\\활용해서 의도적으로 개행을 하고 있다라는 설명을 통해 오류방지\n",
    "html = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1>\\\n",
    "                <p class='style'>웹페이지에서 필요한 데이터를 추출하는 것</p>\\\n",
    "                <p id='body' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "data = soup.find(\"h1\")\n",
    "print(type(soup))\n",
    "print(data)\n",
    "print(data.string)\n",
    "print(data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca479535-f2a6-4bed-a121-05a602fdf2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body> <h1 id=\"title\">[1]크롤링이란?</h1> <p class=\"style\">웹페이지에서 필요한 데이터를 추출하는 것</p> <p align=\"center\" id=\"body\">파이썬을 중심으로 다양한 웹 크롤링 기술 발달</p> </body>\n",
      " [1]크롤링이란? 웹페이지에서 필요한 데이터를 추출하는 것 파이썬을 중심으로 다양한 웹 크롤링 기술 발달 \n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\\활용해서 의도적으로 개행을 하고 있다라는 설명을 통해 오류방지\n",
    "html = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1>\\\n",
    "                <p class='style'>웹페이지에서 필요한 데이터를 추출하는 것</p>\\\n",
    "                <p id='body' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "data = soup.find(\"body\")\n",
    "\n",
    "# string -> 크롤링하고자 하는 대상의 직접적인 텍스트 문자열을 찾아와야 할 때\n",
    "# get_text() -> 자식요소의 텍스트 문자열까지 크롤링하고자 할 때\n",
    "print(data)\n",
    "#print(data.string)#크롤링 해야하는 타겟을 잘 잡지 못했을 경우 None 출력\n",
    "print(data.get_text())\n",
    "print(type(data.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daeb60ba-61a4-46b7-b970-f96ea862715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\\활용해서 의도적으로 개행을 하고 있다라는 설명을 통해 오류방지\n",
    "html = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1>\\\n",
    "                <p class='style'>웹페이지에서 필요한 데이터를 추출하는 것</p>\\\n",
    "                <p id='body' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "data = soup.find(\"p\") #find 메서드 함수는 위에서부터 첫번째만 찾아옴\n",
    "print(data.get_text())\n",
    "print(data.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e29ea018-e2a3-48d7-9218-dad3c8d695bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "파이썬을 중심으로 다양한 웹 크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\\활용해서 의도적으로 개행을 하고 있다라는 설명을 통해 오류방지\n",
    "html = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1>\\\n",
    "                <p class='style'>웹페이지에서 필요한 데이터를 추출하는 것</p>\\\n",
    "                <p id='body' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "data = soup.find_all(\"p\") #find_all 로 모두 찾아오면 list 형식으로 찾아옴\n",
    "#print(data.string) -> 리스트 자료구조에서 string 속성값을 쓸 수 없음.\n",
    "\n",
    "for item in data :\n",
    "    print(item.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2eb23f3b-08f3-4528-8dbc-d36055295703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\" id=\"body\">파이썬을 중심으로 다양한 웹 크롤링 기술 발달</p>\n",
      "파이썬을 중심으로 다양한 웹 크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\\활용해서 의도적으로 개행을 하고 있다라는 설명을 통해 오류방지\n",
    "html = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1>\\\n",
    "                <p class='style'>웹페이지에서 필요한 데이터를 추출하는 것</p>\\\n",
    "                <p id='body' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "#data = soup.find(\"p\", attrs={\"id\":\"body\"})#p태그 중에 id 속성값이 body 인 p 값을 크롤링\n",
    "\n",
    "data = soup.find(\"p\", attrs={\"align\":\"center\"})#p태그 중에 align 속성값이 center 인 p 값을 크롤링\n",
    "\n",
    "print(data)\n",
    "print(data.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fc9836e-7d64-4205-8278-79c2c151d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\" id=\"body02\">파이썬을 중심으로 다양한 웹 크롤링 기술 발달 - 2</p>\n",
      "파이썬을 중심으로 다양한 웹 크롤링 기술 발달 - 2\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\\활용해서 의도적으로 개행을 하고 있다라는 설명을 통해 오류방지\n",
    "html = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1>\\\n",
    "                <p id='body01' align='center'>웹페이지에서 필요한 데이터를 추출하는 것 - 1</p>\\\n",
    "                <p id='body02' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달 - 2</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "#data = soup.find(\"p\", attrs={\"id\":\"body\"})#p태그 중에 id 속성값이 body 인 p 값을 크롤링\n",
    "\n",
    "#data = soup.find(\"p\", attrs={\"id\":\"body02\", \"align\":\"center\"})#attrs 속성값은 딕셔너리 형태로 연장해서 조건에 맞는 크롤링을 할 수 있다.\n",
    "data = soup.find(\"p\", id = \"body02\")#attrs 을 사용하지 않고도 약식으로 찾아올 수도 있다.\n",
    "\n",
    "print(data)\n",
    "print(data.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c23e18c1-c3d4-43bc-b8f1-746f1d89a68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹페이지에서 필요한 데이터를 추출하는 것 - 2\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#\\활용해서 의도적으로 개행을 하고 있다라는 설명을 통해 오류방지\n",
    "html = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id='title'>[1]크롤링이란?</h1>\\\n",
    "                <p class='cssstyle01'>웹페이지에서 필요한 데이터를 추출하는 것 - 1</p>\\\n",
    "                <p class='cssstyle02'>웹페이지에서 필요한 데이터를 추출하는 것 - 2</p>\\\n",
    "                <p id='body01' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달 - 1</p>\\\n",
    "                <p id='body02' align='center'>파이썬을 중심으로 다양한 웹 크롤링 기술 발달 - 2</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#data = soup.find(\"p\", attrs={\"class\":\"cssstyle02\"})#제일 정석정인 방법\n",
    "#data = soup.find(\"p\", class_= \"cssstyle02\")#class값을 이용해서 찾아오고 싶으면 class_ 활용\n",
    "data = soup.find(\"p\", \"cssstyle02\")#class는 특별대우를 받아서 아무런 속성을 쓰지 않으면 class라고 인식한다.\n",
    "\n",
    "print(data.string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
